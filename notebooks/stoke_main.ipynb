{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m \n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtextblob\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TextBlob\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m#import spacy \u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from textblob import TextBlob\n",
    "#import spacy \n",
    "from collections import Counter\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Add the scripts folder to the system path so we can import time_series.py\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# for a folder that contain scripts for modularity \n",
    "sys.path.append(os.path.abspath('../scripts'))\n",
    "sys.path.append(os.path.abspath('../src'))\n",
    "import path\n",
    "\n",
    "from load_data import CSVData\n",
    "from Data_visulization import EDA\n",
    "from financial import FinancialAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = path.get_path_news()\n",
    "file_load = CSVData(folder_path)\n",
    "df = file_load.load_csv_file()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing Unnamed column from the dataset\n",
    "df= df.loc[:,~df.columns.str.contains(\"Unnamed\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39minfo()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate headline length\n",
    "df['headline_length'] = df['headline'].str.len()\n",
    "df['headline_length']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptive statistics for headline length\n",
    "headline_stats = df['headline_length'].describe().T\n",
    "print(\"Descriptive Statistics for Headline Length:\")\n",
    "print(headline_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Count articles by publisher\n",
    "publisher_counts = df['publisher'].value_counts()\n",
    "\n",
    "print(\"\\nTop Publishers and their Article Counts:\")\n",
    "print(publisher_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze Publication Dates\n",
    "\n",
    "# Convert 'date' column to datetime format\n",
    "df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "# Drop rows with invalid or missing dates\n",
    "df = df.dropna(subset=['date'])\n",
    "\n",
    "# Group articles by publication date\n",
    "daily_articles = df.groupby(df['date'].dt.date).size()\n",
    "\n",
    "print(f\"\\nNumber of Articles Published by Date: {daily_articles}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot articles by publisher\n",
    "publisher_counts.head(20).plot(kind='bar', title='Top 20 Publishers by Article Count')\n",
    "plt.xlabel('Publisher')\n",
    "plt.ylabel('Number of Articles')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows where 'date' is NaT and explicitly create a copy\n",
    "df1 = df.dropna(subset=['date']).copy()\n",
    "\n",
    "# Extract additional date components for analysis\n",
    "df1['year'] = df1['date'].dt.year\n",
    "df1['month'] = df1['date'].dt.month\n",
    "df1['day'] = df1['date'].dt.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of articles per day\n",
    "daily_counts = df1['date'].dt.date.value_counts().sort_index()\n",
    "\n",
    "# Plot the trend of articles over time\n",
    "plt.figure(figsize=(12, 6))\n",
    "daily_counts.plot(kind='line', color='blue')\n",
    "plt.title(\"Articles Published Over Time\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Number of Articles\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Count articles by day of the 'month'\n",
    "monthly_counts = df1['month'].value_counts().sort_index()\n",
    "\n",
    "# Plot the frequency of articles by day of the 'month'\n",
    "plt.figure(figsize=(12, 6))\n",
    "monthly_counts.plot(kind='bar', color='orange', alpha=0.7)\n",
    "plt.title(\"Articles Published by Day of the Month\")\n",
    "plt.xlabel(\"Day of the month\")\n",
    "plt.ylabel(\"Number of Articles\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count articles by year\n",
    "yearly_counts = df1['year'].value_counts().sort_index()\n",
    "\n",
    "# Plot the frequency of articles by year\n",
    "plt.figure(figsize=(10, 6))\n",
    "yearly_counts.plot(kind='bar', color='green', alpha=0.7)\n",
    "plt.title(\"Articles Published by year\")\n",
    "plt.xlabel(\"year\")\n",
    "plt.ylabel(\"Number of Articles\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform sentiment analysis\n",
    "def get_sentiment(text):\n",
    "    analysis = TextBlob(text)\n",
    "    if analysis.sentiment.polarity > 0:\n",
    "        return 'Positive'\n",
    "    elif analysis.sentiment.polarity < 0:\n",
    "        return 'Negative'\n",
    "    else:\n",
    "        return 'Neutral'\n",
    "\n",
    "df['sentiment'] = df['headline'].apply(get_sentiment)\n",
    "\n",
    "# Count the number of articles for each sentiment\n",
    "sentiment_counts = df['sentiment'].value_counts()\n",
    "print(f\"\\nSentiment Analysis Results: {sentiment_counts}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Bar chart for sentiment analysis\n",
    "plt.figure(figsize=(8, 6))\n",
    "sentiment_counts.plot(kind='bar', color=['green', 'blue', 'red'], alpha=0.7)\n",
    "\n",
    "# Customize the plot\n",
    "plt.title('Sentiment Analysis: Distribution of Sentiments', fontsize=16)\n",
    "plt.xlabel('Sentiment', fontsize=12)\n",
    "plt.ylabel('Number of Headlines', fontsize=12)\n",
    "plt.xticks(rotation=0)  # Rotate x-axis labels if necessary\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Tokenize and extract keywords\n",
    "def extract_keywords(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    keywords = [word.lower() for word in tokens if word.is_alpha() and word.lower() not in stop_words]\n",
    "    return keywords\n",
    "\n",
    "# Apply the function to the 'headline' column\n",
    "#df['keywords'] = df['headline'].apply(extract_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count most common keywords\n",
    "all_keywords = [keyword for keywords in df['keywords'] for keyword in keywords]\n",
    "common_keywords = Counter(all_keywords).most_common(20)\n",
    "\n",
    "# Print the top 20 keywords\n",
    "print(f\"\\nTop 20 Keywords: {common_keywords}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def analyze_publication_frequency(self, time_unit='D'):\n",
    "        \"\"\" This function anlyzes how the publication frequency varies over time. The time can be, for daily,\n",
    "        for weekly, for monthly, and for hourly frequency.\n",
    "        \"\"\"\n",
    "        # Set 'date' as the index for time series analysis\n",
    "        self.dataframe.set_index('date', inplace=True)\n",
    "\n",
    "        # Resample by the specified time unit and count the number of articles published in each period\n",
    "        publication_frequency = self.dataframe.resample(time_unit).size()\n",
    "\n",
    "        # Plot the publication frequency over time\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        publication_frequency.plot(kind='line', color='blue')\n",
    "        plt.title(f\"Publication Frequency Over Time ({time_unit})\")\n",
    "        plt.xlabel(\"Time\")\n",
    "        plt.ylabel(\"Number of Articles Published\")\n",
    "        plt.grid(True)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Analyze DAILY trends\n",
    "# Extract the date (without time) and count articles published per day\n",
    "df['publication_date'] = df['date'].dt.date\n",
    "daily_trend = df.groupby('publication_date').size()\n",
    "\n",
    "# Plot daily publication trends\n",
    "plt.figure(figsize=(12, 6))\n",
    "daily_trend.plot(kind='line', color='blue')\n",
    "plt.title('Daily Publication Frequency')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Number of Articles Published')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 2. Analyze MONTHLY trends\n",
    "# Group data by year and month, and count articles\n",
    "df['year_month'] = df['date'].dt.to_period('M')  # Format: YYYY-MM\n",
    "monthly_trend = df.groupby('year_month').size()\n",
    "\n",
    "# Plot monthly publication trends\n",
    "plt.figure(figsize=(12, 6))\n",
    "monthly_trend.plot(kind='line', color='green')\n",
    "plt.title('Monthly Publication Frequency')\n",
    "plt.xlabel('Year-Month')\n",
    "plt.ylabel('Number of Articles Published')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Analyze YEARLY trends\n",
    "# Group data by year and count articles\n",
    "df['year'] = df['date'].dt.year\n",
    "yearly_trend = df.groupby('year').size()\n",
    "\n",
    "# Plot yearly publication trends\n",
    "plt.figure(figsize=(12, 6))\n",
    "yearly_trend.plot(kind='bar', color='orange')\n",
    "plt.title('Yearly Publication Frequency')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Number of Articles Published')\n",
    "plt.grid(axis='y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Task 2: Identify unique domains if publishers contain email addresses\n",
    "def extract_domain(publisher):\n",
    "    if isinstance(publisher, str) and '@' in publisher:\n",
    "        return publisher.split('@')[-1]\n",
    "    return None\n",
    "\n",
    "df['publisher_domain'] = df['publisher'].apply(extract_domain)\n",
    "unique_domains = df['publisher_domain'].dropna().value_counts()\n",
    "\n",
    "# Plot the top domains\n",
    "plt.figure(figsize=(12, 6))\n",
    "unique_domains.head(10).plot(kind='bar', color='teal')\n",
    "plt.title('Top 10 Domains by Contribution')\n",
    "plt.xlabel('Domain')\n",
    "plt.ylabel('Number of Articles')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = path.get_path_price()\n",
    "\n",
    "# Create an instance of CSVLoader\n",
    "csv_loader = CSVData(folder_path)\n",
    "\n",
    "# Load CSV files\n",
    "csv_loader.load_data_files()\n",
    "\n",
    "# Merge the loaded dataframes\n",
    "merged_df = csv_loader.merge_dataframes()\n",
    "\n",
    "# Display the first few rows\n",
    "merged_df.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform EDA for stock price\n",
    "stock_price = EDA(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Information and Structure of stoke price\n",
    "stock_price.display_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_price.stat_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_price.univariate_cate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_price.univariate_num()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation Analysis Using Heatmap of Correlation Matrix\n",
    "stock_price.correlation_analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the TimeSeries class with your dataframe\n",
    "finan_data = FinancialAnalysis(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SMA vs. Closing Price:\n",
    "#Compare the SMA_20 with the Close price to identify trends.\n",
    "finan_data.visualize_SMA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finan_data.visualize_RSI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finan_data.visualize_MACD()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date columns to datetime format\n",
    "df['date'] = pd.to_datetime(df['date'], errors='coerce') # news_data\n",
    "merged_df['date'] = pd.to_datetime(merged_df['Date'], errors='coerce') # stock_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize timestamps to only keep the date (no time)\n",
    "df['date'] = df['date'].dt.date   # news_data\n",
    "merged_df['date'] = merged_df['date'].dt.date  # stock_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the two datasets on the date column\n",
    "aligned_data = pd.merge(df, merged_df, on='date', how='inner')\n",
    "aligned_data.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
